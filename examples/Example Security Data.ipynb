{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "150f8aa6",
   "metadata": {},
   "source": [
    "# Example: Security Data\n",
    "\n",
    "This is an example for the keyword extraction and topic modeling function inside of tactic. Please be advised that the similarity based designator matching is more in a beta stage and subject to further improvements.\n",
    "This notebook will apply clustering to a synthetic dataset of mock safety reports in a company. \n",
    "\n",
    "## Import Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b45ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from clustering_pipeline import ClusteringPipeline\n",
    "from importlib import resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b4025",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd343f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PACKAGE_NAME = 'tactic.example_data'\n",
    "RESOURCE_NAME = 'mock_security_incidents.csv'\n",
    "\n",
    "\n",
    "with resources.files(PACKAGE_NAME).joinpath(RESOURCE_NAME).open('r') as f:\n",
    "    df = pd.read_csv(f, , encoding=\"latin1\")\n",
    "\n",
    "print(f\"Loaded {len(df)} records\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c899fb",
   "metadata": {},
   "source": [
    "# Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd8a111",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Overview\n",
    "\n",
    "The workflow performs the following steps:\n",
    " \n",
    "### Initial data exploration**\n",
    "   - Inspect incident type distribution\n",
    "   - Inspect designator distribution\n",
    "   - View sample incidents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a791ec89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"\\nIncident Type Distribution:\")\n",
    "print(df['IncidentType'].value_counts())\n",
    "\n",
    "print(\"\\n\\nDesignator Distribution:\")\n",
    "print(df['Designator'].value_counts())\n",
    "\n",
    "print(\"\\n\\nSample Incidents:\")\n",
    "print(df[['IncidentID', 'IncidentType', 'Designator', 'Narrative']].head(10))\n",
    "\n",
    "\n",
    "\n",
    "from clustering_pipeline import ClusteringPipeline\n",
    "\n",
    "# Initialize pipeline with 'Narrative' as the text column\n",
    "pipeline = ClusteringPipeline(df, text_column='Narrative')\n",
    "print(\"✓ Pipeline initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287dc6fa",
   "metadata": {},
   "source": [
    "\n",
    "### Preprocessing\n",
    "   - Clean text\n",
    "   - Apply custom stopwords\n",
    "   - Optionally remove low-IDF terms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc81085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Preprocessing text data...\")\n",
    "pipeline.preprocess_data(\n",
    "    custom_stopwords=['incident', 'reported', 'employee', 'found'],\n",
    "    low_idf=True,\n",
    "    idf_threshold=1.4\n",
    ")\n",
    "print(\"✓ Preprocessing complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf9631a",
   "metadata": {},
   "source": [
    "### Clustering and Keyword Extraction\n",
    "   - Cluster incidents with UMAP + HDBSCAN using fixed parameters\n",
    "   - Extract top keywords per cluster (TF-IDF and YAKE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dbe075",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\nMethod 1: Clustering with Keyword Extraction\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = pipeline.cluster_and_extract_keywords(\n",
    "    min_cluster_size=15,\n",
    "    n_neighbors=20,\n",
    "    n_components=2,\n",
    "    tf_top_n=5,\n",
    "    yake_top_n=10,\n",
    "    yake_final_n=5, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nCluster Distribution:\")\n",
    "print(results['cluster_summary'])\n",
    "\n",
    "print(\"\\n\\nKeywords by Cluster:\")\n",
    "print(results['keywords'].head(15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ce2092",
   "metadata": {},
   "source": [
    "### Cluster Composition Analysis\n",
    "   - Inspect incident types per cluster\n",
    "   - Calculate percentages per cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467a721",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_with_clusters = results['dataframe']\n",
    "\n",
    "print(\"\\nCluster Composition (Incident Types per Cluster):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for cluster_id in sorted(df_with_clusters['Clusters'].unique()):\n",
    "    if cluster_id == -1:\n",
    "        continue  \n",
    "    \n",
    "    cluster_data = df_with_clusters[df_with_clusters['Clusters'] == cluster_id]\n",
    "    print(f\"\\nCluster {cluster_id} ({len(cluster_data)} incidents):\")\n",
    "    \n",
    "    incident_types = cluster_data['IncidentType'].value_counts()\n",
    "    for incident_type, count in incident_types.items():\n",
    "        percentage = (count / len(cluster_data)) * 100\n",
    "        print(f\"  {incident_type}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0864ea15",
   "metadata": {},
   "source": [
    "### LDA Topic Modeling\n",
    "   - Initialize a separate pipeline for LDA analysis\n",
    "   - Define a dictionary of designators for topic mapping\n",
    "   - Cluster and analyze topics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d857f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline_lda = ClusteringPipeline(df, text_column='Narrative')\n",
    "pipeline_lda.preprocess_data(\n",
    "    custom_stopwords=['incident', 'reported', 'employee', 'found']\n",
    ")\n",
    "\n",
    "print(\"✓ New pipeline initialized for LDA analysis\")\n",
    "\n",
    "designators = {\n",
    "    'THEFT': 'stolen value valued room approximately suspect item missing laptop loss breakin multiple total warehouse phone took incident equipment shoplifting location apprehended retail personal estimated worth',\n",
    "    'VANDALISM': 'floor cleanup repair building estimated camera damage elevator buttons damaged smashed required covered area hallway extinguisher powder discharged shattered glass broken office crew windows dispatched',\n",
    "    'ACCESS': 'access area badge employee unauthorized security building denied attempted visitor individual restricted main lost identified wandering entry deactivated notified used floor vehicle supervisor team open',\n",
    "    'SUSPICIOUS': 'individual security suspicious parking lot person near left floor observed package activity reported building questions behavior asking concerning lobby systems detailed monitored loading dock minutes',\n",
    "    'VIOLENCE': 'security employee threatening employees parties physical separated break room meeting altercation supervisor statements escorted premises hr notified individual threat verbal broke suspended individuals investigation workplace',\n",
    "    'SAFETY': 'building area hazard power electrical shut evacuated called leak discovered electrician notified gas floor triggered team hazmat chemical alarm kitchen spill laboratory given clear smoke',\n",
    "    'POLICY': 'employee policy violation company written area sent used unauthorized vehicle personal logged fleet use issued near parties entrance prohibited detected control sharing smoking building badge',\n",
    "    'CYBER': 'employee phishing reported security suspicious provided detected password fell reset forced scam credentials team attempt engineering social request phone passwords quarantined workstation computer malware department',\n",
    "    'MEDICAL': 'employee care urgent supervisor drove dizziness administered reported severe called headache treated room epipen medical meeting reaction having fainted onsite stable paramedics arrived conference injured',\n",
    "    'FRAUD': 'control documents reports inspection forged discovered falsified quality charges fraud'\n",
    "}\n",
    "\n",
    "print(\"Designators defined:\")\n",
    "for key, value in designators.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nMethod 2: Clustering with LDA Topic Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "topic_results = pipeline_lda.cluster_and_analyze_topics(\n",
    "    min_cluster_size=15,\n",
    "    num_topics=10,\n",
    "    passes=15,\n",
    "    designators=designators\n",
    ")\n",
    "\n",
    "print(\"\\nCluster Summary:\")\n",
    "print(topic_results['cluster_summary'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c0764",
   "metadata": {},
   "source": [
    "### View Topics and Cluster-to-Topic Mappings\n",
    "   - Display top words for each topic\n",
    "   - Map clusters to dominant topics\n",
    "   - Match topics to designators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e8aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lda_model = topic_results['topics']['model']\n",
    "\n",
    "print(\"\\nLDA Topics and Top Words:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for topic_id in range(10):\n",
    "    try:\n",
    "        topic_words = lda_model.lda_model.show_topic(topic_id, topn=10)\n",
    "        print(f\"\\nTopic {topic_id}:\")\n",
    "        words = \", \".join([f\"{word}({prob:.2f})\" for word, prob in topic_words[:7]])\n",
    "        print(f\"  {words}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "print(\"\\nCluster to Topic Mappings:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for cluster_id, topic_ids in topic_results['topics']['cluster_topics'].items():\n",
    "    if isinstance(topic_ids, int):\n",
    "        topic_ids = [topic_ids]\n",
    "    \n",
    "    print(f\"\\nCluster {cluster_id}:\")\n",
    "    for topic_id in topic_ids[:2]:  # Show top 2 topics\n",
    "        try:\n",
    "            topic_words = lda_model.lda_model.show_topic(topic_id, topn=5)\n",
    "            words = \", \".join([word for word, _ in topic_words])\n",
    "            print(f\"  Topic {topic_id}: {words}\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "print(\"\\nTopic to Designator Similarity Scores:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for topic_id in range(10):\n",
    "    matches = topic_results['topics']['topic_designators'].get(topic_id, [])\n",
    "    if matches:\n",
    "        print(f\"\\nTopic {topic_id}:\")\n",
    "        for designator, similarity in matches[:3]:\n",
    "            print(f\"  {designator}: {similarity:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395fc6dd",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "   - Plot cluster distributions across incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b423b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts = topic_results['cluster_summary']['Size'].sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(cluster_counts)), cluster_counts.values)\n",
    "plt.xlabel('Cluster ID')\n",
    "plt.ylabel('Number of Incidents')\n",
    "plt.title('Incident Distribution Across Clusters')\n",
    "plt.xticks(range(len(cluster_counts)), cluster_counts.index, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Cluster distribution plotted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7ba3e",
   "metadata": {},
   "source": [
    "### Validation\n",
    "   - Check cluster purity against known designators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = topic_results['dataframe']\n",
    "\n",
    "print(\"\\nValidation: Cluster Purity Check\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for cluster_id in sorted(df_final['Clusters'].unique()):\n",
    "    if cluster_id == -1:\n",
    "        continue\n",
    "    \n",
    "    cluster_data = df_final[df_final['Clusters'] == cluster_id]\n",
    "    \n",
    "    # Find dominant designator\n",
    "    designator_counts = cluster_data['Designator'].value_counts()\n",
    "    dominant_designator = designator_counts.index[0]\n",
    "    dominant_count = designator_counts.iloc[0]\n",
    "    purity = (dominant_count / len(cluster_data)) * 100\n",
    "    \n",
    "    print(f\"\\nCluster {cluster_id}:\")\n",
    "    print(f\"  Dominant Designator: {dominant_designator}\")\n",
    "    print(f\"  Purity: {purity:.1f}% ({dominant_count}/{len(cluster_data)})\")\n",
    "    print(f\"  All Designators: {dict(designator_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71c73c2",
   "metadata": {},
   "source": [
    "\n",
    "### Export Results\n",
    "    - Save clustered dataset\n",
    "    - Save cluster summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nExporting Results...\")\n",
    "\n",
    "# Save clustered data\n",
    "df_final.to_csv('incidents_with_clusters.csv', index=False)\n",
    "print(\"✓ Saved: incidents_with_clusters.csv\")\n",
    "\n",
    "# Save cluster summary\n",
    "topic_results['cluster_summary'].to_csv('cluster_summary.csv')\n",
    "print(\"✓ Saved: cluster_summary.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
